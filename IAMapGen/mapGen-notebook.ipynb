{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83478aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Reshape, Conv2DTranspose\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.densenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63716e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.8721637 ,  1.4656863 ,  1.3502399 ],\n",
       "        [ 1.4611696 ,  1.0280112 ,  0.7576472 ],\n",
       "        [ 1.8379141 ,  1.4306723 ,  0.8970808 ],\n",
       "        ...,\n",
       "        [ 2.0776608 ,  2.1134453 ,  1.6813945 ],\n",
       "        [ 2.2489083 ,  2.3410363 ,  1.8905448 ],\n",
       "        [ 2.11191   ,  2.2184873 ,  1.7685405 ]],\n",
       "\n",
       "       [[ 1.6666666 ,  1.2731093 ,  1.1236603 ],\n",
       "        [ 0.8960528 ,  0.45028022,  0.18248373],\n",
       "        [ 1.5296686 ,  1.0980393 ,  0.5310677 ],\n",
       "        ...,\n",
       "        [ 1.9064132 ,  1.9033613 ,  1.4896734 ],\n",
       "        [ 1.5981677 ,  1.6232493 ,  1.193377  ],\n",
       "        [ 1.3412963 ,  1.4131653 ,  0.9667976 ]],\n",
       "\n",
       "       [[ 1.5639181 ,  1.1155462 ,  0.94936836],\n",
       "        [ 1.2727973 ,  0.81792724,  0.51363856],\n",
       "        [ 1.6152923 ,  1.1855743 ,  0.6007845 ],\n",
       "        ...,\n",
       "        [ 1.3412963 ,  1.2731093 ,  0.8796516 ],\n",
       "        [ 1.3755459 ,  1.3606442 ,  0.94936836],\n",
       "        [ 1.6152923 ,  1.6407562 ,  1.1759479 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.8207895 ,  1.9733893 ,  1.8208281 ],\n",
       "        [ 0.9131775 ,  1.0630252 ,  0.8622224 ],\n",
       "        [ 0.31381115,  0.41526622,  0.19991292],\n",
       "        ...,\n",
       "        [ 1.6666666 ,  0.95798326, -0.06152498],\n",
       "        [ 2.1804092 ,  1.5182073 ,  0.2522005 ],\n",
       "        [ 1.4782944 ,  0.8004202 , -0.68897593]],\n",
       "\n",
       "       [[ 2.2146587 ,  2.4110641 ,  2.3088455 ],\n",
       "        [ 2.2489083 ,  2.4285715 ,  2.3262744 ],\n",
       "        [ 1.6837914 ,  1.8333333 ,  1.6813945 ],\n",
       "        ...,\n",
       "        [ 1.2727973 ,  0.55532223, -0.4623964 ],\n",
       "        [ 1.4440448 ,  0.7303922 , -0.5321132 ],\n",
       "        [ 1.5467933 ,  0.87044823, -0.6192592 ]],\n",
       "\n",
       "       [[ 1.7351656 ,  1.9208683 ,  1.8905448 ],\n",
       "        [ 2.2146587 ,  2.4110641 ,  2.343704  ],\n",
       "        [ 2.2489083 ,  2.4285715 ,  2.3611329 ],\n",
       "        ...,\n",
       "        [ 1.5296686 ,  0.81792724, -0.20095852],\n",
       "        [ 1.8892884 ,  1.1855743 , -0.07895417],\n",
       "        [ 1.6666666 ,  0.9929972 , -0.49725482]]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Diretório que contém as imagens\n",
    "diretorio = \"mapas/padronizadas/\"\n",
    "txt_file = \"mapas/padronizadas/etiquetas.txt\"\n",
    "\n",
    "def load_images_and_labels(diretorio, txt_file):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    with open(txt_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:  # Verificar se há pelo menos dois elementos na linha\n",
    "                image_path = os.path.join(diretorio, parts[0])  # O primeiro elemento é o nome da imagem\n",
    "                label = parts[1]  # O segundo elemento é a etiqueta\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(label)\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "image_paths, labels = load_images_and_labels(diretorio, txt_file)\n",
    "\n",
    "# Pré-processamento de imagens (redimensionamento e normalização)\n",
    "def preprocess_image(image_path, target_size):\n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "target_size = (256, 256)  # Tamanho desejado das imagens\n",
    "dados_preprocessados = [preprocess_image(path, target_size) for path in image_paths]\n",
    "dados_preprocessados = np.array(dados_preprocessados)\n",
    "dados_preprocessados[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849f260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100  # Mantenha a dimensão do vetor de entrada\n",
    "target_size = (256, 256)  # Tamanho desejado das imagens\n",
    "\n",
    "def build_generator(input_dim, target_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim))\n",
    "    model.add(Dense(np.prod(target_size) * 3, activation='tanh'))  # Saída compatível com 256x256x3\n",
    "    model.add(Reshape(target_size + (3,)))  # Redimensiona para 256x256x3\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = build_generator(input_dim, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07c01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Tamanho da imagem de entrada (deve corresponder ao tamanho das imagens que você está gerando)\n",
    "input_shape = (256, 256, 3)\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c82afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar o discriminador durante o treinamento da GAN\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Entrada para a GAN\n",
    "gan_input = Input(shape=(input_dim,))\n",
    "generated_image = generator(gan_input)\n",
    "\n",
    "# Saída da GAN (a saída do gerador passa pelo discriminador)\n",
    "gan_output = discriminator(generated_image)\n",
    "\n",
    "# Crie o modelo da GAN\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "# Compile a GAN\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214be1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, (examples, input_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    # Normaliza as imagens geradas para o intervalo [0, 1]\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'generated_image_epoch_{epoch}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da4db3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.156014488718938e-05]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_preprocessados = np.array(dados_preprocessados)\n",
    "\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "epochs = 100  # Número de épocas\n",
    "batch_size = 32  # Tamanho do lote\n",
    "sample_interval = 100  # Intervalo para salvar imagens de exemplo\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Treinar o discriminador\n",
    "    idx = np.random.randint(0, len(dados_preprocessados), batch_size)\n",
    "    real_images = dados_preprocessados[idx]\n",
    "    noise = np.random.normal(0, 1, (batch_size, input_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Treinar a GAN\n",
    "    noise = np.random.normal(0, 1, (batch_size, input_dim))\n",
    "    valid_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "\n",
    "    # Imprimir progresso a cada sample_interval épocas\n",
    "    if epoch % (sample_interval * 10) == 0:\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        save_generated_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1))\n",
    "        \n",
    "d_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf645447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.662208557128906]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbd08086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "# Tamanho do vetor de ruído (input)\n",
    "input_dim = 100\n",
    "\n",
    "# Crie um vetor de ruído aleatório\n",
    "noise = np.random.normal(0, 1, (1, input_dim))\n",
    "\n",
    "# Gere uma imagem usando o gerador\n",
    "generated_image = generator.predict(noise)\n",
    "\n",
    "generated_image = generated_image[0]\n",
    "\n",
    "# Converta a imagem de float (entre 0 e 1) para int (entre 0 e 255)\n",
    "generated_image = (generated_image * 255).astype(np.uint8)\n",
    "\n",
    "# Crie uma imagem PIL a partir da matriz NumPy\n",
    "image = Image.fromarray(generated_image)\n",
    "\n",
    "# Salve a imagem com o nome \"ximg.png\" (ou outro formato de imagem, como .jpg, .png, etc.)\n",
    "image.save(\"ximg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05be5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_do_arquivo = 'ganMap.keras'\n",
    "\n",
    "# Salve o modelo GAN completo (incluindo gerador e discriminador) em um único arquivo\n",
    "gan.save(nome_do_arquivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1612f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_gan_carregado = load_model(ganMap.keras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
